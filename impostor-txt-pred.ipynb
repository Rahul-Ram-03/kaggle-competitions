{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22d7b192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home-pc/miniconda3/envs/pytorch-basics/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as N\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import math\n",
    "from torchinfo import summary\n",
    "from IPython.display import clear_output\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ff7139",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES_AND_LABELS = \"./kaggle/input/fake-or-real-the-impostor-hunt/data/train_files_and_ground_truth.csv\"\n",
    "TEST_FILES = \"./kaggle/input/fake-or-real-the-impostor-hunt/data/test_files.csv\"\n",
    "OUT_FILE = \"./kaggle/working/fake-or-real-the-impostor-hunt/submission.csv\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batchSize = 16\n",
    "dModel = 1024\n",
    "maxSeqLen = tokenizer.model_max_length\n",
    "vocabSize = len(tokenizer.get_vocab())\n",
    "nLayers = 8\n",
    "nHeads = 8\n",
    "ffDim = 2048\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47926ef4",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d40448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "\tdef __init__(self, path):\n",
    "\t\tsuper(TrainDataset, self).__init__()\n",
    "\t\tself.__filesAndLabels__: pd.DataFrame = pd.read_csv(path)\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.__filesAndLabels__.shape[0]\n",
    "\t\n",
    "\tdef __getitem__(self, index):\n",
    "\t\tinputPath, groundTruth = self.__filesAndLabels__.iloc[index]\n",
    "\t\tinputText = \"\"\n",
    "\n",
    "\t\twith open(inputPath, 'r') as f:\n",
    "\t\t\tfor line in f.readlines():\n",
    "\t\t\t\tinputText += line + \"\\n\"\n",
    "\t\t\n",
    "\t\treturn inputText, groundTruth\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66348fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "\tdef __init__(self, path):\n",
    "\t\tsuper(TestDataset, self).__init__()\n",
    "\t\tself.__filesAndLabels__: pd.DataFrame = pd.read_csv(path)\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.__filesAndLabels__.shape[0]\n",
    "\t\n",
    "\tdef __getitem__(self, index):\n",
    "\t\tarticleId, fileId, inputPath = self.__filesAndLabels__.iloc[index]\n",
    "\t\tinputText = \"\"\n",
    "\n",
    "\t\twith open(inputPath, 'r') as f:\n",
    "\t\t\tfor line in f.readlines():\n",
    "\t\t\t\tinputText += line + \"\\n\"\n",
    "\t\t\n",
    "\t\treturn articleId, fileId, inputText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18035da",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f02a5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = TrainDataset(FILES_AND_LABELS)\n",
    "testData = TestDataset(TEST_FILES)\n",
    "\n",
    "trainDataloader = DataLoader(trainData, batch_size= batchSize,\n",
    "\t\t\t\t\t\t\t shuffle= True, drop_last= True)\n",
    "testDataLoader = DataLoader(testData, batch_size= batchSize,\n",
    "\t\t\t\t\t\t\tshuffle= True, drop_last= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e965abb9",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb534e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(N.Module):\n",
    "\tclass PositionalEmbedding(N.Module):\n",
    "\t\tdef __init__(self, dModel):\n",
    "\t\t\tsuper().__init__()\n",
    "\t\t\tself.dModel = dModel\n",
    "\n",
    "\t\tdef forward(self, input):\n",
    "\t\t\temb = math.log(10000) / (self.dModel // 2 - 1)\n",
    "\t\t\temb = torch.exp(torch.arange(self.dModel // 2) * -emb)\n",
    "\t\t\temb = input[:, None] * emb[None, :]\n",
    "\t\t\temb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "\t\t\treturn emb\n",
    "\n",
    "\tdef __init__(self, dModel, maxSeqLen, nLayers, nHeads, ffDim, vocabSize, dropout= 0.1):\n",
    "\t\tsuper(Encoder, self).__init__()\n",
    "\t\tencoder = N.TransformerEncoderLayer(d_model= dModel, nhead= nHeads,\n",
    "\t\t\t\t\t\t\t\t\t  \t\tdim_feedforward= ffDim, dropout= dropout,\n",
    "\t\t\t\t\t\t\t\t\t\t\tbatch_first= True)\n",
    "\t\t\n",
    "\t\tself.embeddings = N.Embedding(num_embeddings= vocabSize, embedding_dim= dModel).to(device)\n",
    "\t\tself.posEmb = self.PositionalEmbedding(dModel= dModel)\n",
    "\t\tself.transformerEncoder = N.TransformerEncoder(encoder_layer= encoder, num_layers= nLayers)\n",
    "\t\tself.fc1 = N.Linear(in_features= dModel, out_features= dModel//2)\n",
    "\t\tself.fc2 = N.Linear(in_features= dModel//2, out_features= 2)\n",
    "\t\tself.fc3 = N.Linear(in_features= maxSeqLen * 2, out_features= 1)\n",
    "\n",
    "\tdef forward(self, input, padding_mask):\n",
    "\t\tembs = self.embeddings(input)\n",
    "\t\tbs, l, h = embs.shape\n",
    "\n",
    "\t\tseqIdx = torch.arange(l)\n",
    "\t\tposEmb = self.posEmb(seqIdx).reshape(1, l, h).expand(bs, l, h).to(device)\n",
    "\t\tembs = embs + posEmb\n",
    "\n",
    "\t\tcausalMask = torch.triu(torch.ones(l, l), 1).bool().to(device)\n",
    "\n",
    "\t\toutput = self.transformerEncoder(src= embs, mask= causalMask, \n",
    "\t\t\t\t\t\t\t\t   \t\t src_key_padding_mask= padding_mask)\n",
    "\n",
    "\t\tif(output.isnan().any()):\n",
    "\t\t\traise ValueError\n",
    "\t\t\n",
    "\t\toutput = self.fc1(output)\n",
    "\t\toutput = self.fc2(output).flatten(1,2)\n",
    "\t\toutput: torch.Tensor = self.fc3(output).squeeze(-1)\n",
    "\n",
    "\t\treturn output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d20493",
   "metadata": {},
   "source": [
    "### Model instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3529163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================================================================================================\n",
       "Layer (type (var_name))                       Input Shape               Output Shape              Param #                   Trainable\n",
       "=================================================================================================================================================\n",
       "Encoder (Encoder)                             [16, 512]                 [16]                      --                        True\n",
       "├─Embedding (embeddings)                      [16, 512]                 [16, 512, 1024]           31,254,528                True\n",
       "├─PositionalEmbedding (posEmb)                [512]                     [512, 1024]               --                        --\n",
       "├─TransformerEncoder (transformerEncoder)     --                        [16, 512, 1024]           --                        True\n",
       "│    └─ModuleList (layers)                    --                        --                        --                        True\n",
       "│    │    └─TransformerEncoderLayer (0)       [16, 512, 1024]           [16, 512, 1024]           8,399,872                 True\n",
       "│    │    └─TransformerEncoderLayer (1)       [16, 512, 1024]           [16, 512, 1024]           8,399,872                 True\n",
       "│    │    └─TransformerEncoderLayer (2)       [16, 512, 1024]           [16, 512, 1024]           8,399,872                 True\n",
       "│    │    └─TransformerEncoderLayer (3)       [16, 512, 1024]           [16, 512, 1024]           8,399,872                 True\n",
       "│    │    └─TransformerEncoderLayer (4)       [16, 512, 1024]           [16, 512, 1024]           8,399,872                 True\n",
       "│    │    └─TransformerEncoderLayer (5)       [16, 512, 1024]           [16, 512, 1024]           8,399,872                 True\n",
       "│    │    └─TransformerEncoderLayer (6)       [16, 512, 1024]           [16, 512, 1024]           8,399,872                 True\n",
       "│    │    └─TransformerEncoderLayer (7)       [16, 512, 1024]           [16, 512, 1024]           8,399,872                 True\n",
       "├─Linear (fc1)                                [16, 512, 1024]           [16, 512, 512]            524,800                   True\n",
       "├─Linear (fc2)                                [16, 512, 512]            [16, 512, 2]              1,026                     True\n",
       "├─Linear (fc3)                                [16, 1024]                [16, 1]                   1,025                     True\n",
       "=================================================================================================================================================\n",
       "Total params: 98,980,355\n",
       "Trainable params: 98,980,355\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 508.50\n",
       "=================================================================================================================================================\n",
       "Input size (MB): 0.07\n",
       "Forward/backward pass size (MB): 100.79\n",
       "Params size (MB): 127.13\n",
       "Estimated Total Size (MB): 227.99\n",
       "================================================================================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Encoder(dModel, maxSeqLen, nLayers, nHeads, ffDim, vocabSize)\n",
    "model.to(device)\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_data=[\n",
    "        torch.zeros((batchSize, maxSeqLen), dtype= torch.long).to(device),  # input\n",
    "        torch.zeros((batchSize, maxSeqLen), dtype= torch.bool).to(device)   # padding_mask\n",
    "    ],\n",
    "    col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
    "    row_settings=['var_names'],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a2991",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1800430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 10 of 10\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Batch: 0; Curr batch loss:  0.01250; Curr batch acc.: 100.00\n",
      "Batch: 5; Curr batch loss:  0.00233; Curr batch acc.: 100.00\n",
      "Batch: 10; Curr batch loss:  0.00176; Curr batch acc.: 100.00\n",
      "Avg train loss: 0.01775; Avg train acc.: 1.00000\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr= lr)\n",
    "loss_fn = N.BCEWithLogitsLoss()\n",
    "\n",
    "epochSnapshot: list[dict] = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\tmodel.train()\n",
    "\tclear_output(wait= True)\n",
    "\n",
    "\tprint(f\"Starting epoch {epoch + 1} of {epochs}\\n~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\tepochLoss = 0\n",
    "\tepochAcc = 0\n",
    "\n",
    "\ttorch.cuda.empty_cache()\n",
    "\tgc.collect()\n",
    "\n",
    "\tfor idx, (inputText, groundTruth) in enumerate(trainDataloader):\n",
    "\t\tcurrBatchLoss = 0\n",
    "\t\tcurrBatchAccuracy = 0\n",
    "\t\tgroundTruth = groundTruth.cuda()\n",
    "\n",
    "\t\ttokens = tokenizer(inputText, padding= \"max_length\", \n",
    "\t\t\t\t\t \t   truncation= True, max_length= maxSeqLen,\n",
    "\t\t\t\t\t\t   return_tensors= \"pt\")\n",
    "\n",
    "\t\ttoken_ids = tokens['input_ids'].to(device)\n",
    "\t\tpadding_mask = (~(tokens['attention_mask'].bool())).to(device)\n",
    "\t\tbs = token_ids.shape[0]\n",
    "        \n",
    "        # Shift the input sequence to create the target sequence\n",
    "\t\ttarget_ids = torch.cat((token_ids[:, 1:], \n",
    "\t\t\t\t\t\t\t\ttorch.zeros(bs, 1, device=device).long()), 1)\n",
    "\t\t\n",
    "\t\tpred = model(target_ids, padding_mask)\n",
    "\t\tloss = loss_fn(pred, groundTruth.float())\n",
    "\n",
    "\t\topt.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\topt.step()\n",
    "\n",
    "\t\tcurrBatchLoss = loss.detach().item()\n",
    "\t\tcurrBatchAccuracy += ((pred > 0.5).int() == groundTruth).sum()\n",
    "\n",
    "\t\tepochLoss += currBatchLoss\n",
    "\t\tepochAcc += (currBatchAccuracy / 16)\n",
    "\n",
    "\t\tif(idx % 5 == 0):\n",
    "\t\t\tprint(f\"Batch: {idx}; Curr batch loss: {currBatchLoss: 0.5f}; Curr batch acc.: {currBatchAccuracy/16*100:0.2f}\")\n",
    "\t\t\n",
    "\tepochLoss /= len(trainDataloader)\n",
    "\tepochAcc /= len(trainDataloader)\n",
    "\t\n",
    "\tepochSnapshot.append({\n",
    "\t\t'epoch': f\"{epoch}\",\n",
    "\t\t'train_loss': f\"{epochLoss:0.7f}\",\n",
    "\t\t'train_acc': f\"{epochAcc:0.5f}\",\n",
    "\t})\n",
    "\n",
    "\tprint(f\"Avg train loss: {epochLoss:0.5f}; Avg train acc.: {epochAcc:0.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee34b2e",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8b12826",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "testingPreds: list[dict] = []\n",
    "with torch.inference_mode():\n",
    "\tfor idx, (articleId, fileId, inputText) in enumerate(testDataLoader):\n",
    "\t\ttokens = tokenizer(inputText, padding= \"max_length\", \n",
    "\t\t\t\t\t \t   truncation= True, max_length= maxSeqLen,\n",
    "\t\t\t\t\t\t   return_tensors= \"pt\")\n",
    "\n",
    "\t\ttoken_ids = tokens['input_ids'].to(device)\n",
    "\t\tpadding_mask = (~(tokens['attention_mask'].bool())).to(device)\n",
    "\t\tbs = token_ids.shape[0]\n",
    "        \n",
    "        # Shift the input sequence to create the target sequence\n",
    "\t\ttarget_ids = torch.cat((token_ids[:, 1:], \n",
    "\t\t\t\t\t\t\t\ttorch.zeros(bs, 1, device=device).long()), 1)\n",
    "\t\t\n",
    "\t\tpreds = model(target_ids, padding_mask)\n",
    "\t\t\n",
    "\t\tfor i in range(batchSize):\n",
    "\t\t\ttestingPreds.append({\n",
    "                \"articleId\": articleId[i].item(),\n",
    "                \"fileId\": fileId[i].item(),\n",
    "                \"prediction\": preds[i].item()\n",
    "\t\t\t})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb046df7",
   "metadata": {},
   "source": [
    "### Prepping the submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c0fc02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(testingPreds)\n",
    "\n",
    "submissions_df = df.loc[df.groupby('articleId')['prediction'].idxmax()].reset_index(drop=True)\n",
    "submissions_df.drop(columns= ['prediction'], inplace= True)\n",
    "submissions_df.rename(columns= {\n",
    "\t'articleId': 'id',\n",
    "\t'fileId': 'real_text_id'\n",
    "}, inplace= True)\n",
    "\n",
    "submissions_df.to_csv(OUT_FILE, index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
